{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.misc import imsave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Style and Content Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the dimensions of the style and content images\n",
    "height = 300\n",
    "width = 300\n",
    "\n",
    "content_image = Image.open('images/SAR.jpg')\n",
    "content_image = content_image.resize((width, height))\n",
    "content_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image = Image.open('images/andy.jpg')\n",
    "style_image = style_image.resize((width, height))\n",
    "style_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocess the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert the images into arrays for numerical processing\n",
    "# The images occur in RGB pixel channel format creating the 3 dimensions in addition to length and width\n",
    "# length x width x 3 dimensions\n",
    "# We add an additional dimesnion of 1 to allow us to concatenate the style and content images\n",
    "\n",
    "content_array = np.asarray(content_image, dtype='float32')\n",
    "content_array = np.expand_dims(content_array, axis=0)\n",
    "print(content_array.shape)\n",
    "\n",
    "style_array = np.asarray(style_image, dtype='float32')\n",
    "style_array = np.expand_dims(style_array, axis=0)\n",
    "print(style_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the mean RGB pixel value of the training set (ImageNet)\n",
    "# invert the arrays from RGB to BGR\n",
    "\n",
    "content_array[:, :, :, 0] -= 103.939\n",
    "content_array[:, :, :, 1] -= 116.779\n",
    "content_array[:, :, :, 2] -= 123.68\n",
    "content_array = content_array[:, :, :, ::-1]\n",
    "\n",
    "style_array[:, :, :, 0] -= 103.939\n",
    "style_array[:, :, :, 1] -= 116.779\n",
    "style_array[:, :, :, 2] -= 123.68\n",
    "style_array = style_array[:, :, :, ::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Keras' variables for the images\n",
    "\n",
    "content_image = backend.variable(content_array)\n",
    "style_image = backend.variable(style_array)\n",
    "combination_image = backend.placeholder((1, height, width, 3))\n",
    "\n",
    "# Concatenate the content and style images\n",
    "\n",
    "input_tensor = backend.concatenate([content_image, style_image, combination_image], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load a Pre-Trained VGG-16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# keep all layers except classification layers\n",
    "\n",
    "layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function we want to minimise can be decomposed into three distinct parts: \n",
    "# 1) content loss \n",
    "# 2) style loss \n",
    "# 3) total variation loss.\n",
    "\n",
    "# relative importance of these terms are determined by a set of scalar weights\n",
    "\n",
    "content_weight = 0.1\n",
    "style_weight = 1.0\n",
    "total_variation_weight = 1.0\n",
    "\n",
    "# initialize the total loss function and add to it\n",
    "\n",
    "loss = backend.variable(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###          a) Content Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(content, generated):\n",
    "    return 0.5*(backend.sum(backend.square(content - generated)))\n",
    "\n",
    "layer_features = layers['block2_conv1']\n",
    "content_image_features = layer_features[0, :, :, :]\n",
    "generated_image_features = layer_features[2, :, :, :]\n",
    "\n",
    "loss += content_weight * content_loss(content_image_features, generated_image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Style Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = backend.dot(features, backend.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_loss(style, generated):\n",
    "    S = gram_matrix(style)\n",
    "    G = gram_matrix(generated)\n",
    "    channels = 3\n",
    "    size = height * width\n",
    "    return backend.sum(backend.square(S - G)) / (4. * (channels ** 2) * (size ** 2))\n",
    "\n",
    "# ‘conv1 1’, ‘conv2 1’, ‘conv3 1’, ‘conv4 1’ and ‘conv5 1’\n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = layers[layer_name]\n",
    "    style_image_features = layer_features[1, :, :, :]\n",
    "    generated_image_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_image_features, generated_image_features)\n",
    "    loss += (style_weight / len(feature_layers)) * sl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Total Variation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    a = backend.square(x[:, :height-1, :width-1, :] - x[:, 1:, :width-1, :])\n",
    "    b = backend.square(x[:, :height-1, :width-1, :] - x[:, :height-1, 1:, :])\n",
    "    return backend.sum(backend.pow(a + b, 1.25))\n",
    "\n",
    "loss += total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Gradient Function and Loss Optimization \n",
    "Now that we have our input images massaged and our loss function calculators in place, all we have left to do is define gradients of the total loss relative to the combination image, and use these gradients to iteratively improve upon our combination image to minimise the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = backend.gradients(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "outputs += grads\n",
    "f_outputs = backend.function([combination_image], outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, height, width, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1].flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 255, (1, height, width, 3)) - 128.\n",
    "\n",
    "iterations = 12\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    end_time = time.time()\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Image Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape((height, width, 3))\n",
    "x = x[:, :, ::-1]\n",
    "x[:, :, 0] += 103.939\n",
    "x[:, :, 1] += 116.779\n",
    "x[:, :, 2] += 123.68\n",
    "x = np.clip(x, 0, 255).astype('uint8')\n",
    "\n",
    "Image.fromarray(x).save('images/experiments 2/exp.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are several resources available for implementing Neural Style Tranfer (NST) using Tensorflow and Keras in Python. hnarayanan from Github offers a clear and concise implementation of NST and I have used his work as a framework for my own.\n",
    "\n",
    "link to hnarayanan's work: https://github.com/hnarayanan/artistic-style-transfer/blob/master/notebooks/6_Artistic_style_transfer_with_a_repurposed_VGG_Net_16.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
